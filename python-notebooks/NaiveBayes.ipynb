{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Machine Learning and Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Convert the Data into a Feature Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Map All the Words to a Feature Vector\n",
    "# Each word is mapped to an index in a feature vector\n",
    "def createTrainingData(words):\n",
    "    arr = numpy.zeros(len(index_map));\n",
    "    for word in words:\n",
    "        arr[index_map[word]] += 1;\n",
    "    return arr;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the Data + Some Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file = '../data/final.csv'\n",
    "df = pd.read_csv(file)\n",
    "\n",
    "x_label = \"Review\"\n",
    "y_label = \"Sentiment\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/ipykernel/__main__.py:20: FutureWarning: comparison to `None` will result in an elementwise object comparison in the future.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Data is of Shape:  (999, 2420)\n",
      "Label Data is of Shape:  (999,)\n"
     ]
    }
   ],
   "source": [
    "index_map = dict(); # maps words to an index\n",
    "count = 0; # the index being incremented\n",
    "\n",
    "## Map each word to a specific index.\n",
    "## This will let us create feature vector\n",
    "## where each word is mapped to an index.\n",
    "for sentence in df[x_label].tolist():\n",
    "    words = sentence.split(\" \");\n",
    "    for word in words:\n",
    "        if not word in index_map:\n",
    "            index_map[word] = count;\n",
    "            count += 1;\n",
    "\n",
    "# Create the Feature Training Data (x)\n",
    "train_x = None\n",
    "for arr in df[x_label].tolist():\n",
    "    words = arr.split(\" \");\n",
    "    \n",
    "    # vertically stack each feature vector to create feature matrix\n",
    "    if train_x == None: train_x = createTrainingData(words)\n",
    "    else: train_x = numpy.vstack((train_x, createTrainingData(words)))\n",
    "        \n",
    "# Create the Label Training Data (y)\n",
    "train_y = numpy.array(df[y_label].tolist());\n",
    "\n",
    "print \"Feature Data is of Shape: \", train_x.shape\n",
    "print \"Label Data is of Shape: \", train_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function to Train the Classifer and Run it Against Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB as ml_algo\n",
    "from sklearn import metrics as metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the accuracy of the test data\n",
    "# when predicted against fitted training data\n",
    "def train(x,y,tx,ty):\n",
    "    classifier = ml_algo() # can swap out ml_algo for different Naive Bayes implementation\n",
    "    classifier.fit(x, y) # fit the feature and labeled data\n",
    "    return metrics.accuracy_score(test_y, classifier.predict(test_x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Accuracy Using K-Fold Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k = 5; # number for k fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 - fold cross validation\n",
      "-----------------------------\n",
      "k = 0 : Accuracy: 0.738693\n",
      "k = 1 : Accuracy: 0.688442\n",
      "k = 2 : Accuracy: 0.653266\n",
      "k = 3 : Accuracy: 0.718593\n",
      "k = 4 : Accuracy: 0.768844\n",
      "\n",
      "Average Accuracy: 0.713567839196\n"
     ]
    }
   ],
   "source": [
    "b_length = len(train_x)/k; # the bucket length\n",
    "sum_acc = 0; # Use this for average accuracy\n",
    "\n",
    "print k, \"- fold cross validation\"\n",
    "print \"-----------------------------\"\n",
    "\n",
    "for i in range(0,k):\n",
    "    s_i = i*b_length;\n",
    "    f_i = s_i + b_length;\n",
    "   \n",
    "    test_x = train_x[s_i:f_i]\n",
    "    test_y = train_y[s_i:f_i]\n",
    "    \n",
    "    ntx = numpy.vstack((train_x[0:s_i],train_x[f_i:len(train_x)]))\n",
    "    nty = numpy.append(train_y[0:s_i],train_y[f_i:len(train_y)])\n",
    "    \n",
    "    score = train(ntx,nty,test_x,test_y)\n",
    "    print 'k =',i,': Accuracy: %f' % score\n",
    "    sum_acc += score;\n",
    "    \n",
    "print '\\nAverage Accuracy:', sum_acc / 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
